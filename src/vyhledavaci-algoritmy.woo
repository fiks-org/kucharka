.Chapter Řadící a vyhledávací algoritmy
  label: chap-radici-vyhledavaci-algo


Všichni máme zkušenosti ze života, kdy jsme něco hledali v nějaké tabulce, nebylo to seřazené
a my jsme si přáli, aby byla seřazená a nemuseli jsme procházet všechno. Pročítače to mají podobně
hodně algoritmů je mnohem efektivnějších, když mají vstup seřazený. Ale jak ho seřadíme?


V této kapitole se podíváme na několik řaďících algoritmů a poté i na nějaké vyhledávací, ať už v seřazeném
nebo neseřazeném vstupu. Také si znovu připomeneme počítání složitostí a ukážeme si jak se dokazují zbylé dvě
vlastnosti algoritmů, korektnost a konečnost.


.Section Řadící algoritmy
  label: sec-radici-algo

Pro řazení je důležité, aby pro prvky, které chceme seřadit existovalo nějaké "úplné uspořádání".reference.1,
to je zjednodušeně operátor~<, kterým můžeme libovolné dva prvky porovnat.
  1:
    link: https://cs.wikipedia.org/wiki/Line%C3%A1rn%C3%AD_uspo%C5%99%C3%A1d%C3%A1n%C3%AD


U řadících algoritmů nás navíc zajímá ještě jedna vlastnost a tou je "stabilita".notion.1. Mějme vstupní posloupnost
$p_1, p_2, \dots, p_n$. Řadící algoritmus je stabilní, pokud pro každé dva prvky $p_i$ a $p_j$, které si jsou rovny platí,
že jejich vzájemné pořadí na výstupu se je stejné jako jejich pořadí na vstupu.
Jinými slovy, pokud $p_i = p_j$ a $i < j$, pak se $p_i$ na výstupu objeví před $p_j$.


.Procedure:
  title: Select sort
  label: algo-select-sort
  index: sort!select sort

  Jeden z nejjednodušších algoritmů na seřazení je select sort. Princip spočívá v tom, že z posloupnosti
  vybírám ten nejmenší prvek a zařadím ho na konec seřazené části. Intuitivně to dává smysl, my si ukážeme,
  jak dokázat, že výsledek bude opravdu seřazený formálně.


  V každém kroku máme dvě, potenciálně prázdné, posloupnosti, vstupní $p$ a výstupní $s$. Jeden krok spočívá
  ve vybrání minimálního prvku, říkejme mu $p_m$ z $p$ a vložení na konec $s$. $p_m$ bude určitě větší nebo roven
  všem z $s$, protože všechny prvky $s$ byly někdy minimální v $p$, jinak se do $s$ dostat nemohli. Kdyby $p_m$ nebyl
  všetší nebo roven všem prvkům z $s$, tak to znamená, že existuje $s_x$ z $s$ takový, že $p_m$ < $s_x$. Ale to je spor s tím,
  že $s_x$ byl minimální v $p$. Takže $p_m$ je větší než všechny prvky v $s$ a patří na konec.


  Dobře je zde i vidět, že algoritmus skončí, každý krok zmenší posloupnost $p$ o jedna a protože je konečná,
  tak bude někdy prázdná a všechny její prvky budou v $s$, což bude seřazený výstup.


  Implementace by pak mohla vypadat v pseudokódu takhle, všimněte si, že se nepřesouvají prvky z jednoho pole
  do druhého, ale řadí se inplace. Je to určité šetření časem a místem. Jako cvičení si zkuste navrhnout implementaci,
  která by postupoval podle předchozího popisu a přesouvala prvky z jedné posloupnosti do druhé.

  !pseudocode:

    \PROCEDURE{SelectSort}{$p_1, p_2, \dots, p_n$}
      \FOR {$i = 1, \dots, n $ }
        \STATE {$m = i$}
        \FOR {$j = i+1, \dots, n $ }
          \IF {$p_j < p_m$}
            \STATE $m = j$
          \ENDIF
        \ENDFOR
        \STATE swap($p_i$, $p_m$)
      \ENDFOR
    \ENDPROCEDURE


  S touto implementací se můžeme podívat více na složitosti. Navíc oproti vstupu zde používáme jednu proměnou pro držení minima
  a další ve swapu, to znamená že poměťová složitost je $\lanO(1)$ navíc oproti vstupu. Časová složitost je trochu složitější výpočet,
  vnější forloop se provede $n$-krát, ale vnitřní závisí na hodnotě $i$, která se každou iteraci mění. A provede se tedy $(n-i)$-krát.
  Všechny operace (porovnání a swap) v loopu trvají konstatní dobu. Takže počet kroků můžeme napsat jako
  $\sum_{i=1}^{n} n-i$. To je ale jednoduchá aritmetická řada, jejíž součet můžeme napsat jako
  $\frac{n}{2}*(n-1) = \frac{n^2-n}{2}$, což je zhora omezeno $n^2$, takže časová složitost bude $\lanO(n^2)$.


  Zůstává nám zodpovědět, jestli je algoritmus stabilní nebo ne. Zkuste si to nejdřív sami.


.Solution:
  title: Stabilita select sortu
  lable: sol-select-sort-stability

  Na tuto otázku neexistuje jednoznačná odpověď, takže správná je "záleží".emphasize.
  Záleží na implementaci hledání minima, pseudokód v tomto textu je napsán tak, aby algoritmus stabilní byl,
  existuje však způsob nalezení minima, který stabilní nebude.


.Procedure:
  title: Bubble sort
  label: algo-bubble-sort
  index: sort!bubble sort

  Bublání je častá technika používaná v algoritmech, tento algoritmus funguje podobně, jako když máte mísu s různě velkými kamínky
  a zatřepete s ní a pomalu malé kamínky propadají do spod, zatímco ty větší zůstanou na vrchu.


  Algoritmus opakovaně prochází celým polem a porovnává sousední dvojice prvků. Pokud pro dvojici prvků $p_i$ a $p_{i+1}$ platí $p_{i} > p_{i+1}$, tak
  se prvky prohodí. Tím se postupně větší prvky přesouvají doprava a menší doleva. Po dostatečně mnoha průchodech pak bude pole seřazené.

  
  Bude tohle opravdu fungovat? Zkuste si sami dokázat korektnost bubble sortu - tedy, že nakonci bude pole skutečně seřazené,
  a zkuste vymyslet jakou bude mít náš algoritmus časovou a paměťovou složitost.


.Solution:
  title: Korektnost bubble sortu
  lable: sol-bubble-sort-correctness

  Všimněme si, že po prvním průchodu algoritmus posune největší prvek na konec pole, pokud na této pozici už nebyl. Po druhém průchodu posune druhý největší prvek
  na předposlední místo v poli, pokud tam už nebyl. Takže obecně po $k$-tém průchodu je na konci pole správně seřazených alespoň $k$ největších prvků. Pokud pole má
  $n$ prvků, pak po $n$ iteracích bude na konci pole správně seřazených alespoň $n$ největších prvků, jinak řečeno, pole bude seřazené.

  Tedy pokud chceme, aby bylo seřazeno $n$ prvků, tak to bude trvat nanejvíš $n$ průchodů polem - průchodů může být ale potřeba daleko méně, např. pokud začneme hned se správně
  seřazeným polem (dokážete najít nějaké pole, které bude potřebovat všech $n$ průchodů?). Takže algoritmus skončí a jeho výsledkem bude seřazené pole.


.Solution:
  title: Časová složitost bubble sortu
  lable: sol-bubble-sort-time-complexity

  Už víme, že průchodů bude v nejhorším případě $n$. Takže nás zajímá, jak dlouho trvá jeden průchod. Při jednom prchůchodu se každý prvek porovná se
  sousedem, takových porovnání bude $n-1$. Takže výsledná časová složitost je $\lanO(n^2)$. Protože víme, že $k$-tý průchod bude posledních $k$ prvků seřezených, tak můžeme
  algoritmus trochu optimalizovat a porovnávat jenom prvních $n-k$ prvků. Takže pak máme $\sum_{k=0}^{n-1} n-k = \frac{n(n+1)}{2} = \lanO(n^2)$.


.Solution:
  title: Prostorová složitost bubble sortu
  lable: sol-bubble-sort-space-complexity

  Až na pár pomocných proměných (iterační nebo při prohazování) nepotřebuje algortmus žádnou paměť navíc, takže paměťová složitost je $\lanO(1)$.


Hurá! Nyní už víme jak řadit a dokonce známe rovnou dva algoritmy řazení. Oba algoritmy běží v nejhorším případě v čase $\lanO(n^2)$. Je to dobré? Je to špatné?
Na tyto otázky obecně nejde moc dobře odpovědět, pokud neznáme vstupní data. Správně bychom si měli spíš položit otázku: Existují i reychlejší algoritmy?


Odpověď na tuto otázku je pozitivní a v následující sekci vám představíme jeden známý algoritmus řazení pracující v (asymptoticky) rychlejším čase.
Půjde o algoritmus pracující na bázi "rozděl a panuj".emphasize (anglicky "divide and conquer".emphasize), o které se obecně pobavíme později. Prozatím stačí vědět, že celý princip
spočívá v rozdělení původního problému na menší celky, které umíme řešit, a následně pak jednotlivá řešení spojit dohromady.


.Procedure:
  title: Quick sort
  index: sort!quick sort

  Princip quicksortu je víceméně jednoduchý. Má-li pole nejvýše jeden prvek, pole rovnou
  vrátíme. Jinak vybereme z pole prvek $a_i$ (tzv. "pivota".notion) a rozdělíme pole
  na levou $L$, prostřední $S$ a pravou část $P$ tak, že všechny prvky $L$ jsou menší než $a_i$,
  všechny prvky stejné hodnoty $a_i$ zařadíme do $S$ a zbytek prvků do $P$.
  Rekurzivně seřadíme levou $L$ a pravou $P$ část a nakonec pouze "slepíme".quoted části
  $L$, $S$ a $P$ za sebe a výsledné pole vrátíme.


  Nejprve si ukážeme konečnost algoritmu (bez ní nemá smysl korektnost vůbec zkoumat)
  "rozmyslete!".footnote. Tu dokážeme indukcí "pravidlo říká, že kde je rekurze, 
  tam je indukce, a naopak :)".footnote podle velikosti pole. Má-li pole nejvýše jeden
  prvek, tak algoritmus jistě skončí, protože takové pole pouze vrátíme a žádnou další
  operaci už neprovádíme. Tím máme dokázan základní krok. V indukčním kroku předpokládejme,
  že máme pole velikosti $n > 1$ a že algoritmus je konečný pro všechny pole menší
  velikosti. Protože má pole víc než jeden prvek, tak dle algoritmu pole rozdělíme
  na tři části $L$, $S$ a $P$, a na části $L$ a $P$ algoritmus rekurznivně spustíme znovu.
  Protože
  obě části mají velikost menší než $n$ "rozmyslete!".footnote, algoritmus spuštěný na
  obou částech $L$ i $P$ skončí. Po seřazení obou částí algoritmus pouze slepí všechny
  tři části za sebe, což je jistě konečná operace. Tím máme dokázan indukční krok,
  a spolu se základním krokem je tedy algoritmus konečný.


  Důkaz korektnosti by vypadal obdobně. V základním kroku využijeme pozorování, že pole
  o nejvýše jednom prvku je triviálně seřazeno. V indukčním kroku zase fakt, že slepení
  všech tří již seřazených částí za sebe nemůže rozbít celkové seřazení vstupního pole
  "laskavý čtenář si to dokáže precizně, např. sporem".footnote.


  Pozorný čtenář si jistě všiml, že pouze takový důkaz korektnosti by neprošel,
  neboť jsme si stále neřekli nic o tom, jak hledat pivota. Způsobů je mnoho, můžeme
  ho vybírat náhodně, deterministicky jako vždy první prvek pole, nebo jako minimum
  či medián hodnot v poli. Ať už ho budeme vybírat jakkoli, důkaz korektnosti i
  konečnosti bude fungovat vždy stejně "rozmyslete".footnote (ale některé
  způsoby nemusí být úplně nejvhodnější, jak se dozvíte u analýzy časové složitosti).
  

  Předtím než se pustíme na časovou složitost quicksortu, si zavedeme
  tzv. "strom rekurzivních volání".notion.1 (SRV), což je zakořeněný strom, kde vrcholy
  odpovídají jednotlivým rekurzivním voláním (specificky kořen stromu 
  odpovídá prvnímu zavolání funkce) a vrcholy $s_1,\dots,s_k$ jsou synové vrcholu
  $x$ právě tehdy, když odpovídají jednotlivým rekurzivním voláním v průběhu
  vyhodnocování vrcholu $x$.
    1:
      index: strom rekurzivních volání


  Pokud si u každého vrcholu poznamenáme velikost vstupního pole, může SRV vypadat
  např. následovně:

  !tikz:
    filename: marakuja-sort-figure

      \node {n}
        child {node {1}}
        child {node {$n - 1$}
          child {node {1}}
          child {node {$n - 2$}
            child {node {1}}
            child {node {$n - 3$}
              child {node {1}}
              child {node {$\dots$}
                child {node {1}}
                child {node {$n - (n - 1)$}}
              }
            }
          }
        };

  Leví synové odpovídají části $L$ a praví synové odpovídají části $P$.
 

.Solution:
  title: Časová složitost quicksortu
  lable: sol-quicksort-time-comlexity

  Začneme složitostí v nejhorším případě. 


  Pokud budeme pokaždé dělit pole na dvě stejně velké části, tak budeme dělit $\log_2(n)$ krát než dojdeme k polím o jednom prvku.

  !tikz:
    filename: quicksort-figure

      \node {n}
        child {node {$\frac{n}{2}$}
          child {node {$\frac{n}{4}$}
            child {node {$\frac{n}{8}$}
            }
            child {node {$\frac{n}{8}$}
            }
          }
          child {node {$\frac{n}{4}$}
            child {node {$\frac{n}{8}$}
            }
            child {node {$\frac{n}{8}$}
            }
          }
        }
        child {node {$\frac{n}{2}$}
          child {node {$\frac{n}{4}$}
            child {node {$\frac{n}{8}$}
            }
            child {node {$\frac{n}{8}$}
            }
          }
          child {node {$\frac{n}{4}$}
            child {node {$\frac{n}{8}$}
            }
            child {node {$\frac{n}{8}$}
            }
          }
        };


  Na $k$-té vrstvě tohoto stromu se nachází $2^{k-1}$ částí. A pro každou z nich provedeme práci $\lanO(\frac{n}{2^{k-1}})$. Takže
  na $k$-té vrstvě provedeme $2^{k-1} \cdot \lanO(\frac{n}{2^{k-1}})$ práce. To vychází na $\lanO(n)$ času ztráveného na jedné vrstvě.
  Vrstev je jak už jsme si řekli $\log_2(n)$, takže výsledná časová složitost je $\lanO(n*\log(n))$.


  Nyní si povíme o výběru prvku $a_i$. Tomuto prvku budeme říkat "pivot".notion. Byli bychom nejraději, kdyby pivot byl "medián".notion. 
  Dle definice je medián prvek na prostřední pozici "seřazeného pole".emphasize. Má-li pole sudý počet prvků, pak střed tvoří dva prvky
  a vybereme jeden z nich. Medián nám pole dle úvodu tohoto důkazu rozdělí pole přibližně na dvě stejně velké části.
  

  Stačí tedy najít medián v neseřazeném poli a máme vyhráno. Bohužel pro nás, najít medián není výpočetně snadná operace. (Ví se že medián nelze najít rychleji než v čase
  $\lanO(n\cdot\log(n))?)$. Místo toho můžeme využít takzvaných skoromediánů. "Skoromediány".notion.1 jsou prvky, které se nachází ve druhé a třetí čtvrtině seřazeného pole.
  Pokud vybereme za pivot skoromedián, tak se pole rozdělí na dvě části o $\frac{n}{4}$ a $\frac{3n}{4}$ prvcích. Se velikost pole co musíme seřadit bude na každé vrstvě zmenšovat
  alespoň na $\frac34n$. Než se dostaneme k poli o jednom prvku, tak to bude trvat $\log_\frac43 n$ což je $\lanO(\log n)$. Na jedné vrstvě provedeme
  $\lanO(n)$ operací, takže výsledek je stále $\lanO(n\log n)$. Jenže na výběr skoromediánu jako pivota máme jenom $50\%$ pravděpodobnost, takže v půlce případů,
  vybereme špatného pivota. To ale neznamená nic jiného, než že bude strom rozdělování pole dvakrát tak velký, což pořád vede na $\lanO(n\log n)$ časovou složitost.
  To nám bude stačit, pokud se chcete dovědět více, podívejte se na kapitolu 11 "Průvodce"@2
    1:
      index: skoromedián
    2:
      link: http://pruvodce.ucw.cz/


.Remark:
  title: Další popisy quicksortu

  V jiné literatuře můžete narazit i na jiné popisy quicksortu. Jedním z nich je např. ten, kdy pole místo dvou částí, rozdělíme na tři. (Nějak) zvolíme jeden prvek $a_i$
  a pole rozdělíme na část s prvky menší než $a_i$, část s prvky rovnými $a_i$ a na část s prvky většími než $a_i$. Rekurzivně řadíme pouze první a poslední část, neboť prostřední
  část je již triviálně seřazená. V operaci slepování pak pouze slepíme první, prostřední a poslední část za sebe. Prvek $a_i$ nazýváme \textbf{pivot}.


.Chapter Řadící a vyhledávací algoritmy
  label: chap-radici-vyhledavaci-algo


Všichni máme zkušenosti ze života, kdy jsme něco hledali v nějaké tabulce, nebylo to seřazené
a my jsme si přáli, aby byla seřazená a nemuseli jsme procházet všechno. Pročítače to mají podobně
hodně algoritmů je mnohem efektivnějších, když mají vstup seřazený. Ale jak ho seřadíme?


V této kapitole se podíváme na několik řaďících algoritmů a poté i na nějaké vyhledávací, ať už v seřazeném
nebo neseřazeném vstupu. Také si znovu připomeneme počítání složitostí a ukážeme si jak se dokazují zbylé dvě
vlastnosti algoritmů, korektnost a konečnost.


.Section Řadící algoritmy
  label: sec-radici-algo

Pro řazení je důležité, aby pro prvky, které chceme seřadit existovalo nějaké "úplné uspořádání".reference.1,
to je zjednodušeně operátor~<, kterým můžeme libovolné dva prvky porovnat.
  1:
    link: https://cs.wikipedia.org/wiki/Line%C3%A1rn%C3%AD_uspo%C5%99%C3%A1d%C3%A1n%C3%AD


U řadících algoritmů nás navíc zajímá ještě jedna vlastnost a tou je "stabilita".notion.1. Mějme vstupní posloupnost
$p_1, p_2, \dots, p_n$. Řadící algoritmus je stabilní, pokud pro každé dva prvky $p_i$ a $p_j$, které si jsou rovny platí,
že jejich vzájemné pořadí na výstupu se je stejné jako jejich pořadí na vstupu.
Jinými slovy, pokud $p_i = p_j$ a $i < j$, pak se $p_i$ na výstupu objeví před $p_j$.


.Procedure:
  title: Select sort
  label: algo-select-sort
  index: sort!select sort

  Jeden z nejjednodušších algoritmů na seřazení je select sort. Princip spočívá v tom, že z posloupnosti
  vybírám ten nejmenší prvek a zařadím ho na konec seřazené části. Intuitivně to dává smysl, my si ukážeme,
  jak dokázat, že výsledek bude opravdu seřazený formálně.


  V každém kroku máme dvě, potenciálně prázdné, posloupnosti, vstupní $p$ a výstupní $s$. Jeden krok spočívá
  ve vybrání minimálního prvku, říkejme mu $p_m$ z $p$ a vložení na konec $s$. $p_m$ bude určitě větší nebo roven
  všem z $s$, protože všechny prvky $s$ byly někdy minimální v $p$, jinak se do $s$ dostat nemohli. Kdyby $p_m$ nebyl
  všetší nebo roven všem prvkům z $s$, tak to znamená, že existuje $s_x$ z $s$ takový, že $p_m$ < $s_x$. Ale to je spor s tím,
  že $s_x$ byl minimální v $p$. Takže $p_m$ je větší než všechny prvky v $s$ a patří na konec.


  Dobře je zde i vidět, že algoritmus zkončí, každý krok zmenší posloupnost $p$ o jedna a protože je konečná,
  tak bude někdy prázdná a všechny její prvky budou v $s$, což bude seřazený výstup.


  Implementace by pak mohla vypadat v pseudokódu takhle, všimněte si, že se nepřesouvají prvky z jednoho pole
  do druhého, ale řadí se inplace. Je to určité šetření časem a místem. Jako cvičení si zkuste navrhnout implementaci,
  která by postupoval podle předchozího popisu a přesouvala prvky z jedné posloupnosti do druhé.

  !pseudocode:

    \PROCEDURE{SelectSort}{$p_1, p_2, \dots, p_n$}
      \FOR {$i = 1, \dots, n $ }
        \STATE {$m = i$}
        \FOR {$j = i+1, \dots, n $ }
          \IF {$p_j < p_m$}
            \STATE $m = j$
          \ENDIF
        \ENDFOR
        \STATE swap($p_i$, $p_m$)
      \ENDFOR
    \ENDPROCEDURE


  S touto implementací se můžeme podívat více na složitosti. Navíc oproti vstupu zde používáme jednu proměnou pro držení minima
  a další ve swapu, to znamená že poměťová složitost je $\lanO(1)$ navíc oproti vstupu. Časová složitost je trochu složitější výpočet,
  vnější forloop se provede $n$-krát, ale vnitřní závisí na hodnotě $i$, která se každou iteraci mění. A provede se tedy $(n-i)$-krát.
  Všechny operace (porovnání a swap) v loopu trvají konstatní dobu. Takže počet kroků můžeme napsat jako
  $\sum_{i=1}^{n} n-i$. To je ale jednoduchá aritmetická řada, jejíž součet můžeme napsat jako
  $\frac{n}{2}*(n-1) = \frac{n^2-n}{2}$, což je zhora omezeno $n^2$, takže časová složitost bude $\lanO(n^2)$.


  Zůstává nám zodpovědět, jestli je algoritmus stabilní nebo ne. Zkuste si to nejdřív sami.


.Solution:
  title: Stabilita select sortu
  lable: sol-select-sort-stability

  Na tuto otázku neexistuje jednoznačná odpověď, takže správná je "záleží".emphasize.
  Záleží na implementaci hledání minima, pseudokód v tomto textu je napsán tak, aby algoritmus stabilní byl,
  existuje však způsob nalezení minima, který stabilní nebude.


.Procedure:
  title: Bubble sort
  label: algo-bubble-sort
  index: sort!bubble sort

  Bublání je častá technika používaná v algoritmech, tento algoritmus funguje podobně, jako když máte mísu s různě velkými kamínky
  a zatřepete s ní a pomalu malé kamínky propadají do spod, zatímco ty větší zůstanou na vrchu.


  Algoritmus opakovaně prochází celým polem a porovnává sousední dvojice prvků. Pokud pro dvojici prvků $p_i$ a $p_{i+1}$ platí $p_{i} > p_{i+1}$, tak
  se prvky prohodí. Tím se postupně větší prvky přesouvají doprava a menší doleva. Po dostatečně mnoha průchodech pak bude pole seřazené.

  
  Bude tohle opravdu fungovat? Zkuste si sami dokázat korektnost bubble sortu - tedy, že nakonci bude pole skutečně seřazené,
  a zkuste vymyslet jakou bude mít náš algoritmus časovou a paměťovou složitost.


.Solution:
  title: Korektnost bubble sortu
  lable: sol-bubble-sort-correctness

  Všimněme si, že po prvním průchodu algoritmus posune největší prvek na konec pole, pokud na této pozici už nebyl. Po druhém průchodu posune druhý největší prvek
  na předposlední místo v poli, pokud tam už nebyl. Takže obecně po $k$-tém průchodu je na konci pole správně seřazených alespoň $k$ největších prvků. Pokud pole má
  $n$ prvků, pak po $n$ iteracích bude na konci pole správně seřazených alespoň $n$ největších prvků, jinak řečeno, pole bude seřazené.

  Tedy pokud chceme, aby bylo seřazeno $n$ prvků, tak to bude trvat nanejvíš $n$ průchodů polem - průchodů může být ale potřeba daleko méně, např. pokud začneme hned se správně
  seřazeným polem (dokážete najít nějaké pole, které bude potřebovat všech $n$ průchodů?). Takže algoritmus skončí a jeho výsledkem bude seřazené pole.


.Solution:
  title: Časová složitost bubble sortu
  lable: sol-bubble-sort-time-complexity

  Už víme, že průchodů bude v nejhorším případě $n$. Takže nás zajímá, jak dlouho trvá jeden průchod. Při jednom prchůchodu se každý prvek porovná se
  sousedem, takových porovnání bude $n-1$. Takže výsledná časová složitost je $\lanO(n^2)$. Protože víme, že $k$-tý průchod bude posledních $k$ prvků seřezených, tak můžeme
  algoritmus trochu optimalizovat a porovnávat jenom prvních $n-k$ prvků. Takže pak máme $\sum_{k=0}^{n-1} n-k = \frac{n(n+1)}{2} = \lanO(n^2)$.


.Solution:
  title: Prostorová složitost bubble sortu
  lable: sol-bubble-sort-space-complexity

  Až na pár pomocných proměných (iterační nebo při prohazování) nepotřebuje algortmus žádnou paměť navíc, takže paměťová složitost je $\lanO(1)$.


Jako u každého algoritmu nás zajímá jestli to jde rychleji. Jde to rychleji. Obecně jsou používané dva algoritmy. Než si o nich ale přečtete,
zkuste vymyslet něco lepšího, pokud nic nevymyslíte nic se neděje aspoň nějaké myšlení tím procvičíte.


Oba algoritmy používají metodu zvanou "rozděl a panuj".emphasize (anglicky "divide and conquer".emphasize). O této metodě se dozvíte více později.
Zatím stačí vědět, že funguje na principu rozdělení problému na menší, které umíme vyřešít a následné spojení řešení.


.Procedure:
  title: Quick sort
  index: sort!quick sort

  Algoritmus vypadá jednoduše, rozdělím si pole na dvě stejně velké části. Kde všechny prvky v jedné budou větší než všechny prvky v druhé.
  Tyto dvě části seřadím a slepím za sebe a mám hotovo.


  Popis pěkný, ale o algoritmu nám to moc neřeklo. Jak seřadím ty dvě části? Jak pole rozdělím? Odpověď na první otázku je poměrně přímočará, pomocí quicksortu.
  To však přináší další otázky. Skončí algoritmus, když se volá furt dokola? Bude opravdu seřazený? Všiměme si, že pole o jednom prvku je triviálně seřazeno, a pokud
  budu dělit pole na celočíselné části, tak se někdy musím zastavit na polích o jednom prvku. Takže ano, algoritmus skončí a protože při dělení na dvě části
  rozdělím pole tak, že v jedné části jsou všechny prvky větší než všechny prvky v té druhé, tak mi po jejich seřazení opravdu stačí je slepit za sebe. Nemůže se
  totiž stát, že by jeden z prvků z menší části měl být někde mezi prvky z větší nebo naopak, to by byl spor se způsobem rozdělení.


  Dokázali jsme konečnost a korektnost, teď se podrobněji podíváme na druhou položenou otázku. Jak pole rozdělím? Než si přečtete odpověď, zkuste se nad tím zamyslet.


  Většinou se quicksort popisuje trochu jinak, a to tak, že se pole rozdělí na tři části. Vybere se jeden prvek (prostřední část) a všechny se stejnou hodnotou.
  A pak se pole rozdělí na prvky menší než vybraný prvek a na prvky větší. Čímý vlastně máme náš původní popis, jenom při slepování vlepíme mezi části
  ještě jednu s vybraným prvekem. Vybranému prvku se říká "pivot".emphasize.


  Už víme, jak rozdělit pole na části. Teď jak vybrat pivota? Ideálně bychom chtěli aby to byl medián "prostřední prvek v seřazené posloupnosti".footnote. Tím by se povedlo rozdělit pole na dvě stejně velké části
  jak bylo v původním popisu. Tak super, vybereme medián a máme vyhráno. Výpočet složitostí opět necháme na čtenáři i když v tomto případě by mohla být středoškolská
  matematika nedostačující, věříme ve vaše schopnosti.


.Solution:
  title: Časová složitost quick sortu

  První krok je rozdělit pole na části. To jde zvládnout jedním průchodem, takže $\lanO(n)$. Slepení částí pak bude v nejhorším případě také $\lanO(n)$,
  překopírování všech prvků do jednoho pole. Dvě části z těch na které jsme pole rozdělili musíme seřadit. Obě pole ale budou menší, v nejhorším případě
  $\frac{n}{2}$. Pro tyto části musíme provést to samé.

  Pokud budeme pokaždé dělit pole na dvě stejně velké části, tak budeme dělit $\log_2(n)$ krát než dojdeme k polím o jednom prvku.

  !tikz:
    filename: quicksort-figure

      \node {n}
        child {node {$\frac{n}{2}$}
          child {node {$\frac{n}{4}$}
            child {node {$\frac{n}{8}$}
            }
            child {node {$\frac{n}{8}$}
            }
          }
          child {node {$\frac{n}{4}$}
            child {node {$\frac{n}{8}$}
            }
            child {node {$\frac{n}{8}$}
            }
          }
        }
        child {node {$\frac{n}{2}$}
          child {node {$\frac{n}{4}$}
            child {node {$\frac{n}{8}$}
            }
            child {node {$\frac{n}{8}$}
            }
          }
          child {node {$\frac{n}{4}$}
            child {node {$\frac{n}{8}$}
            }
            child {node {$\frac{n}{8}$}
            }
          }
        };

  Na $k$-té vrstvě tohoto stromu se nachází $2^{k-1}$ částí. A pro každou z nich provedeme práci $\lanO(\frac{n}{2^{k-1}})$. Takže
  na $k$-té vrstvě provedeme $2^{k-1} \cdot \lanO(\frac{n}{2^{k-1}})$ práce. To vychází na $\lanO(n)$ času ztráveného na jedné vrstvě.
  Vrstev je jak už jsme si řekli $\log_2(n)$, takže výsledná časová složitost je $\lanO(n*\log(n))$.


  Pozorní z vás už určitě křičí, že jsme nezapočítali výběr pivota. Jako pivot bychom rádi medián, ale na to musíme pole seřadit$\dots$
  

  Nejjednodužší výber pivota je vybrat náhodně nějaký prvek. Jenže to s sebou nese problémy, pokud je jako pivot vybrán největší prvek, tak se
  pole nerozdělí na stejně velké části jako jsme počítali, ale na jednu o jedna menší a na druhou kterou nemusíme řadit. Nepotřebujeme však vybrat přesně medián,
  můžeme využít skoromediánů. "Skoromediány".notion.1 jsou prvky, které se nachází ve druhé a třetí čtvrtině seřazeného pole. Pokud vybereme za pivot skoro medián,
  tak se pole rozdělí na dvě části o $\frac{n}{4}$ a $\frac{3n}{4}$ prvcích. Se velikost pole co musíme seřadit bude na každé vrstvě zmenšovat
  alespoň na $\frac34n$. Než se dostaneme k poli o jednom prvku, tak to bude trvat $\log_\frac43 n$ což je $\lanO(\log n)$. Na jedné vrstvě provedeme
  $\lanO(n)$ operací, takže výsledek je stále $\lanO(n\log n)$. Jenže na výběr skoromediánu jako pivota máme jenom $50\%$ pravděpodobnost, takže v půlce případů,
  vybereme špatného pivota. To ale neznamená nic jiného, než že bude strom rozdělování pole dvakrát tak velký, což pořád vede na $\lanO(n\log n)$ časovou složitost.
  To nám bude stačit, pokud se chcete dovědět více, podívejte se na kapitolu 11 "Průvodce"@2
    1:
      index: skoromedián
    2:
      link: http://pruvodce.ucw.cz/



.Procedure:
  title: Merge sort
  lable: algo-merge-sort
  index: sort!merge sort

  Podobně jako quick sort, i tento algoritmus rozdělí pole na dvě části, ty seřadí, a následně spojí. Liší se však ve způsobu rozdělování a spojování.
  Zatímco quicksort složitě rozděluje a jednoduše spojuje. Mergesort to dělá naopak, pole rozdělí na stejně velké části, ať už rozseknutím v půlce, nebo 
  prvky na liché pozici do jedné části a na sudé pozici do druhé. Tyto dvě části rekurzivně seřadí opět mergesortem. Spojení seřazených polí do jednoho
  si pak můžeme představit jako dvě hromádky karet, které chceme spojit do jedné seřazené. Vezmeme vždy tu menší kartu z vrhchu obou hromádek. A zařadíme na konec
  nového spojeného balíčku.


.Figure:
  label: merge-sort-diagram

  !dot:
    filename: mergesort-diagram

      digraph G{
        bgcolor="transparent";
        124[label="1, 2, 4"]
        12[label="1, 2"]
        "6, 3, 5, 1, 2, 4" -> "6, 3, 5"
        "6, 3, 5, 1, 2, 4" -> "1, 2, 4"
        "6, 3, 5" -> "6, 3"
        "6, 3, 5" -> "5"
        "6, 3" -> "6"
        "6, 3" -> "3"
        "1, 2, 4" -> "1, 2"
        "1, 2, 4" -> "4"
        "1, 2" -> "1"
        "1, 2" -> "2"
        "6" -> "3, 6"
        "3" -> "3, 6"
        "3, 6" -> "3, 5, 6"
        "5" -> "3, 5, 6"
        "1" -> 12
        "2" -> 12
        12 -> 124
        "4" -> 124
        "3, 5, 6" -> "1, 2, 3, 4, 5, 6"
        124 -> "1, 2, 3, 4, 5, 6"
      }


  .caption:

    Vizualizace rozdělování a slučování polí v algoritmu merge sort.

